{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì½œë ˆìŠ¤í…Œë¡¤ ì˜ˆì¸¡ ëª¨ë¸(ì‹¤íŒ¨)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "file_path = \"./data/health_2023_cleaned_final.csv\"\n",
    "df = pd.read_csv(file_path, encoding='utf-8', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/health_2023_cleaned_final.csv', encoding='utf-8')\n",
    "df = df[['ì„±ë³„ì½”ë“œ', 'ì—°ë ¹ëŒ€ì½”ë“œ(5ì„¸ë‹¨ìœ„)', 'ì‹ ì¥(5cmë‹¨ìœ„)', 'ì²´ì¤‘(5kgë‹¨ìœ„)', 'í—ˆë¦¬ë‘˜ë ˆ', 'ì´ì½œë ˆìŠ¤í…Œë¡¤']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='ì´ì½œë ˆìŠ¤í…Œë¡¤').values\n",
    "y = df['ì´ì½œë ˆìŠ¤í…Œë¡¤'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)  # (ìƒ˜í”Œ ìˆ˜, íƒ€ì„ìŠ¤í…, ì±„ë„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. MLP ëª¨ë¸ ì •ì˜\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # íšŒê·€ ì¶œë ¥\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# 5. í•™ìŠµ\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"./data/health_2023_cleaned_final.csv\")\n",
    "\n",
    "# 2. íŒŒìƒ ë³€ìˆ˜ ìƒì„±\n",
    "df['BMI'] = (df['ì²´ì¤‘(5kgë‹¨ìœ„)'] + 2.5) / ((df['ì‹ ì¥(5cmë‹¨ìœ„)'] + 2.5) / 100) ** 2\n",
    "df['í—ˆë¦¬ì‹ ì¥ë¹„'] = df['í—ˆë¦¬ë‘˜ë ˆ'] / (df['ì‹ ì¥(5cmë‹¨ìœ„)'] + 2.5)\n",
    "\n",
    "# 3. ê²°ì¸¡ì¹˜ ì œê±°\n",
    "required_cols = [\n",
    "    'ì—°ë ¹ëŒ€ì½”ë“œ(5ì„¸ë‹¨ìœ„)', 'ì„±ë³„ì½”ë“œ', 'ì‹ ì¥(5cmë‹¨ìœ„)', 'ì²´ì¤‘(5kgë‹¨ìœ„)', 'í—ˆë¦¬ë‘˜ë ˆ',\n",
    "    'í¡ì—°ìƒíƒœ', 'ìŒì£¼ì—¬ë¶€', 'ìˆ˜ì¶•ê¸°í˜ˆì••', 'ì´ì™„ê¸°í˜ˆì••', 'ì‹ì „í˜ˆë‹¹(ê³µë³µí˜ˆë‹¹)',\n",
    "    'BMI', 'í—ˆë¦¬ì‹ ì¥ë¹„', 'HDLì½œë ˆìŠ¤í…Œë¡¤'\n",
    "]\n",
    "df = df.dropna(subset=required_cols)\n",
    "\n",
    "# 4. ì…ë ¥ / ì¶œë ¥ ì •ì˜\n",
    "X = df[[\n",
    "    'ì—°ë ¹ëŒ€ì½”ë“œ(5ì„¸ë‹¨ìœ„)', 'ì„±ë³„ì½”ë“œ', 'ì‹ ì¥(5cmë‹¨ìœ„)', 'ì²´ì¤‘(5kgë‹¨ìœ„)', 'í—ˆë¦¬ë‘˜ë ˆ',\n",
    "    'í¡ì—°ìƒíƒœ', 'ìŒì£¼ì—¬ë¶€', 'ìˆ˜ì¶•ê¸°í˜ˆì••', 'ì´ì™„ê¸°í˜ˆì••', 'ì‹ì „í˜ˆë‹¹(ê³µë³µí˜ˆë‹¹)',\n",
    "    'BMI', 'í—ˆë¦¬ì‹ ì¥ë¹„'\n",
    "]]\n",
    "y = np.log1p(df['HDLì½œë ˆìŠ¤í…Œë¡¤'])  # ë¡œê·¸ ë³€í™˜ ì ìš©\n",
    "\n",
    "# 5. ì •ê·œí™”\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 6. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "model = XGBRegressor(n_estimators=200, max_depth=4, learning_rate=0.05, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 8. ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)  # ë¡œê·¸ ë³µì›\n",
    "y_true = np.expm1(y_test)\n",
    "\n",
    "print(f\"[HDLì½œë ˆìŠ¤í…Œë¡¤ ì˜ˆì¸¡ ê²°ê³¼ - XGBoost]\")\n",
    "print(f\"RÂ²: {r2_score(y_true, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # 2.15.1 ì´ ì¶œë ¥ë¼ì•¼ í•¨\n",
    "print(dir(tf))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"ğŸ“Š MAE:\", mae)\n",
    "print(\"ğŸ“Š MSE:\", mse)\n",
    "print(\"ğŸ“ˆ RÂ²:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
