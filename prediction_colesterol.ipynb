{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì½œë ˆìŠ¤í…Œë¡¤ ì˜ˆì¸¡ ëª¨ë¸(ì‹¤íŒ¨)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "file_path = \"./data/health_2023_cleaned_final.csv\"\n",
    "df = pd.read_csv(file_path, encoding='utf-8', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/health_2023_cleaned_final.csv', encoding='utf-8')\n",
    "df = df[['ì„±ë³„ì½”ë“œ', 'ì—°ë ¹ëŒ€ì½”ë“œ(5ì„¸ë‹¨ìœ„)', 'ì‹ ì¥(5cmë‹¨ìœ„)', 'ì²´ì¤‘(5kgë‹¨ìœ„)', 'í—ˆë¦¬ë‘˜ë ˆ', 'ì´ì½œë ˆìŠ¤í…Œë¡¤']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='ì´ì½œë ˆìŠ¤í…Œë¡¤').values\n",
    "y = df['ì´ì½œë ˆìŠ¤í…Œë¡¤'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)  # (ìƒ˜í”Œ ìˆ˜, íƒ€ì„ìŠ¤í…, ì±„ë„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jungeun/Desktop/á„Œá…¥á†¼á„‹á…³á†«/cholesterol-prediction-nhis/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 656us/step - loss: 0.4141 - mae: 0.3361 - val_loss: 0.0510 - val_mae: 0.1782\n",
      "Epoch 2/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 638us/step - loss: 0.0533 - mae: 0.1830 - val_loss: 0.0514 - val_mae: 0.1792\n",
      "Epoch 3/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 665us/step - loss: 0.0519 - mae: 0.1803 - val_loss: 0.0543 - val_mae: 0.1839\n",
      "Epoch 4/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 593us/step - loss: 0.0511 - mae: 0.1789 - val_loss: 0.0512 - val_mae: 0.1788\n",
      "Epoch 5/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 600us/step - loss: 0.0508 - mae: 0.1783 - val_loss: 0.0507 - val_mae: 0.1774\n",
      "Epoch 6/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 599us/step - loss: 0.0508 - mae: 0.1782 - val_loss: 0.0497 - val_mae: 0.1756\n",
      "Epoch 7/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 594us/step - loss: 0.0505 - mae: 0.1778 - val_loss: 0.0526 - val_mae: 0.1811\n",
      "Epoch 8/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 599us/step - loss: 0.0502 - mae: 0.1771 - val_loss: 0.0510 - val_mae: 0.1781\n",
      "Epoch 9/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 624us/step - loss: 0.0500 - mae: 0.1769 - val_loss: 0.0502 - val_mae: 0.1764\n",
      "Epoch 10/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 653us/step - loss: 0.0497 - mae: 0.1761 - val_loss: 0.0504 - val_mae: 0.1771\n",
      "Epoch 11/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 643us/step - loss: 0.0503 - mae: 0.1773 - val_loss: 0.0495 - val_mae: 0.1753\n",
      "Epoch 12/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 655us/step - loss: 0.0499 - mae: 0.1767 - val_loss: 0.0532 - val_mae: 0.1819\n",
      "Epoch 13/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 616us/step - loss: 0.0498 - mae: 0.1764 - val_loss: 0.0525 - val_mae: 0.1807\n",
      "Epoch 14/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 646us/step - loss: 0.0499 - mae: 0.1766 - val_loss: 0.0499 - val_mae: 0.1764\n",
      "Epoch 15/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 630us/step - loss: 0.0492 - mae: 0.1752 - val_loss: 0.0500 - val_mae: 0.1764\n",
      "Epoch 16/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 686us/step - loss: 0.0496 - mae: 0.1761 - val_loss: 0.0498 - val_mae: 0.1757\n",
      "Epoch 17/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 601us/step - loss: 0.0492 - mae: 0.1754 - val_loss: 0.0498 - val_mae: 0.1757\n",
      "Epoch 18/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 621us/step - loss: 0.0497 - mae: 0.1763 - val_loss: 0.0515 - val_mae: 0.1789\n",
      "Epoch 19/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 613us/step - loss: 0.0493 - mae: 0.1755 - val_loss: 0.0505 - val_mae: 0.1772\n",
      "Epoch 20/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 640us/step - loss: 0.0493 - mae: 0.1757 - val_loss: 0.0498 - val_mae: 0.1759\n",
      "Epoch 21/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 632us/step - loss: 0.0493 - mae: 0.1754 - val_loss: 0.0498 - val_mae: 0.1757\n",
      "Epoch 22/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 636us/step - loss: 0.0495 - mae: 0.1759 - val_loss: 0.0505 - val_mae: 0.1770\n",
      "Epoch 23/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 621us/step - loss: 0.0492 - mae: 0.1757 - val_loss: 0.0513 - val_mae: 0.1783\n",
      "Epoch 24/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 595us/step - loss: 0.0493 - mae: 0.1757 - val_loss: 0.0496 - val_mae: 0.1756\n",
      "Epoch 25/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 599us/step - loss: 0.0494 - mae: 0.1755 - val_loss: 0.0496 - val_mae: 0.1755\n",
      "Epoch 26/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 669us/step - loss: 0.0493 - mae: 0.1756 - val_loss: 0.0496 - val_mae: 0.1756\n",
      "Epoch 27/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 654us/step - loss: 0.0493 - mae: 0.1757 - val_loss: 0.0496 - val_mae: 0.1755\n",
      "Epoch 28/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 600us/step - loss: 0.0494 - mae: 0.1761 - val_loss: 0.0500 - val_mae: 0.1762\n",
      "Epoch 29/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 599us/step - loss: 0.0493 - mae: 0.1755 - val_loss: 0.0498 - val_mae: 0.1760\n",
      "Epoch 30/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 616us/step - loss: 0.0494 - mae: 0.1757 - val_loss: 0.0494 - val_mae: 0.1751\n",
      "Epoch 31/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 595us/step - loss: 0.0491 - mae: 0.1753 - val_loss: 0.0496 - val_mae: 0.1757\n",
      "Epoch 32/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 605us/step - loss: 0.0497 - mae: 0.1763 - val_loss: 0.0495 - val_mae: 0.1753\n",
      "Epoch 33/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 597us/step - loss: 0.0493 - mae: 0.1754 - val_loss: 0.0502 - val_mae: 0.1765\n",
      "Epoch 34/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 597us/step - loss: 0.0493 - mae: 0.1755 - val_loss: 0.0495 - val_mae: 0.1753\n",
      "Epoch 35/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 600us/step - loss: 0.0491 - mae: 0.1749 - val_loss: 0.0500 - val_mae: 0.1762\n",
      "Epoch 36/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 607us/step - loss: 0.0494 - mae: 0.1757 - val_loss: 0.0497 - val_mae: 0.1756\n",
      "Epoch 37/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 596us/step - loss: 0.0492 - mae: 0.1755 - val_loss: 0.0500 - val_mae: 0.1763\n",
      "Epoch 38/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 599us/step - loss: 0.0489 - mae: 0.1750 - val_loss: 0.0494 - val_mae: 0.1751\n",
      "Epoch 39/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 590us/step - loss: 0.0492 - mae: 0.1755 - val_loss: 0.0496 - val_mae: 0.1754\n",
      "Epoch 40/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 600us/step - loss: 0.0491 - mae: 0.1754 - val_loss: 0.0494 - val_mae: 0.1752\n",
      "Epoch 41/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 592us/step - loss: 0.0490 - mae: 0.1753 - val_loss: 0.0495 - val_mae: 0.1754\n",
      "Epoch 42/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 599us/step - loss: 0.0491 - mae: 0.1754 - val_loss: 0.0498 - val_mae: 0.1760\n",
      "Epoch 43/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 597us/step - loss: 0.0492 - mae: 0.1753 - val_loss: 0.0494 - val_mae: 0.1752\n",
      "Epoch 44/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 598us/step - loss: 0.0493 - mae: 0.1755 - val_loss: 0.0499 - val_mae: 0.1760\n",
      "Epoch 45/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 598us/step - loss: 0.0491 - mae: 0.1753 - val_loss: 0.0494 - val_mae: 0.1751\n",
      "Epoch 46/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 589us/step - loss: 0.0492 - mae: 0.1756 - val_loss: 0.0497 - val_mae: 0.1758\n",
      "Epoch 47/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 593us/step - loss: 0.0489 - mae: 0.1751 - val_loss: 0.0495 - val_mae: 0.1754\n",
      "Epoch 48/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 599us/step - loss: 0.0490 - mae: 0.1751 - val_loss: 0.0494 - val_mae: 0.1751\n",
      "Epoch 49/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 593us/step - loss: 0.0491 - mae: 0.1751 - val_loss: 0.0495 - val_mae: 0.1755\n",
      "Epoch 50/50\n",
      "\u001b[1m6653/6653\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 597us/step - loss: 0.0491 - mae: 0.1750 - val_loss: 0.0496 - val_mae: 0.1757\n"
     ]
    }
   ],
   "source": [
    "# 4. MLP ëª¨ë¸ ì •ì˜\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # íšŒê·€ ì¶œë ¥\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# 5. í•™ìŠµ\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HDLì½œë ˆìŠ¤í…Œë¡¤ ì˜ˆì¸¡ ê²°ê³¼ - XGBoost]\n",
      "RÂ²: 0.2285\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"./data/health_2023_cleaned_final.csv\")\n",
    "\n",
    "# 2. íŒŒìƒ ë³€ìˆ˜ ìƒì„±\n",
    "df['BMI'] = (df['ì²´ì¤‘(5kgë‹¨ìœ„)'] + 2.5) / ((df['ì‹ ì¥(5cmë‹¨ìœ„)'] + 2.5) / 100) ** 2\n",
    "df['í—ˆë¦¬ì‹ ì¥ë¹„'] = df['í—ˆë¦¬ë‘˜ë ˆ'] / (df['ì‹ ì¥(5cmë‹¨ìœ„)'] + 2.5)\n",
    "\n",
    "# 3. ê²°ì¸¡ì¹˜ ì œê±°\n",
    "required_cols = [\n",
    "    'ì—°ë ¹ëŒ€ì½”ë“œ(5ì„¸ë‹¨ìœ„)', 'ì„±ë³„ì½”ë“œ', 'ì‹ ì¥(5cmë‹¨ìœ„)', 'ì²´ì¤‘(5kgë‹¨ìœ„)', 'í—ˆë¦¬ë‘˜ë ˆ',\n",
    "    'í¡ì—°ìƒíƒœ', 'ìŒì£¼ì—¬ë¶€', 'ìˆ˜ì¶•ê¸°í˜ˆì••', 'ì´ì™„ê¸°í˜ˆì••', 'ì‹ì „í˜ˆë‹¹(ê³µë³µí˜ˆë‹¹)',\n",
    "    'BMI', 'í—ˆë¦¬ì‹ ì¥ë¹„', 'HDLì½œë ˆìŠ¤í…Œë¡¤', 'ì¹˜ì•„ìš°ì‹ì¦ìœ ë¬´', 'ì¹˜ì„'\n",
    "]\n",
    "df = df.dropna(subset=required_cols)\n",
    "\n",
    "# 4. ì…ë ¥ / ì¶œë ¥ ì •ì˜\n",
    "X = df[[\n",
    "    'ì—°ë ¹ëŒ€ì½”ë“œ(5ì„¸ë‹¨ìœ„)', 'ì„±ë³„ì½”ë“œ', 'ì‹ ì¥(5cmë‹¨ìœ„)', 'ì²´ì¤‘(5kgë‹¨ìœ„)', 'í—ˆë¦¬ë‘˜ë ˆ',\n",
    "    'í¡ì—°ìƒíƒœ', 'ìŒì£¼ì—¬ë¶€', 'ìˆ˜ì¶•ê¸°í˜ˆì••', 'ì´ì™„ê¸°í˜ˆì••', 'ì‹ì „í˜ˆë‹¹(ê³µë³µí˜ˆë‹¹)',\n",
    "    'BMI', 'í—ˆë¦¬ì‹ ì¥ë¹„', 'ì¹˜ì•„ìš°ì‹ì¦ìœ ë¬´', 'ì¹˜ì„'\n",
    "]]\n",
    "y = np.log1p(df['HDLì½œë ˆìŠ¤í…Œë¡¤'])  # ë¡œê·¸ ë³€í™˜ ì ìš©\n",
    "\n",
    "# 5. ì •ê·œí™”\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 6. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "model = XGBRegressor(n_estimators=200, max_depth=4, learning_rate=0.05, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 8. ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)  # ë¡œê·¸ ë³µì›\n",
    "y_true = np.expm1(y_test)\n",
    "\n",
    "print(f\"[HDLì½œë ˆìŠ¤í…Œë¡¤ ì˜ˆì¸¡ ê²°ê³¼ - XGBoost]\")\n",
    "print(f\"RÂ²: {r2_score(y_true, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n",
      "['AggregationMethod', 'Assert', 'CriticalSection', 'DType', 'DeviceSpec', 'GradientTape', 'Graph', 'IndexedSlices', 'IndexedSlicesSpec', 'Module', 'Operation', 'OptionalSpec', 'RaggedTensor', 'RaggedTensorSpec', 'RegisterGradient', 'SparseTensor', 'SparseTensorSpec', 'Tensor', 'TensorArray', 'TensorArraySpec', 'TensorShape', 'TensorSpec', 'TypeSpec', 'UnconnectedGradients', 'Variable', 'VariableAggregation', 'VariableSynchronization', '_API_MODULE', '_KerasLazyLoader', '__all__', '__builtins__', '__cached__', '__compiler_version__', '__cxx11_abi_flag__', '__cxx_version__', '__doc__', '__file__', '__git_version__', '__internal__', '__loader__', '__monolithic_build__', '__name__', '__operators__', '__package__', '__path__', '__spec__', '__version__', '_api', '_compat', '_current_file_location', '_current_module', '_fi', '_initializers', '_inspect', '_kernel_dir', '_ll', '_losses', '_major_api_version', '_metrics', '_module_dir', '_module_util', '_name', '_names_with_underscore', '_optimizers', '_os', '_plugin_dir', '_pywrap_tensorflow', '_running_from_pip_package', '_s', '_scheme', '_site', '_site_packages_dirs', '_sys', '_sysconfig', '_tf2', '_tf_api_dir', '_tf_dir', '_tf_uses_legacy_keras', 'abs', 'acos', 'acosh', 'add', 'add_n', 'approx_top_k', 'argmax', 'argmin', 'argsort', 'as_dtype', 'as_string', 'asin', 'asinh', 'assert_equal', 'assert_greater', 'assert_less', 'assert_rank', 'atan', 'atan2', 'atanh', 'audio', 'autodiff', 'autograph', 'batch_to_space', 'bfloat16', 'bitcast', 'bitwise', 'bool', 'boolean_mask', 'broadcast_dynamic_shape', 'broadcast_static_shape', 'broadcast_to', 'case', 'cast', 'check_pinned', 'clip_by_global_norm', 'clip_by_norm', 'clip_by_value', 'compat', 'complex', 'complex128', 'complex64', 'concat', 'cond', 'config', 'constant', 'constant_initializer', 'control_dependencies', 'conv', 'conv2d_backprop_filter_v2', 'conv2d_backprop_input_v2', 'convert_to_tensor', 'cos', 'cosh', 'cumsum', 'custom_gradient', 'data', 'debugging', 'device', 'distribute', 'divide', 'double', 'dtensor', 'dtypes', 'dynamic_partition', 'dynamic_stitch', 'edit_distance', 'eig', 'eigvals', 'einsum', 'ensure_shape', 'equal', 'errors', 'executing_eagerly', 'exp', 'expand_dims', 'experimental', 'extract_volume_patches', 'eye', 'feature_column', 'fftnd', 'fill', 'fingerprint', 'float16', 'float32', 'float64', 'floor', 'foldl', 'foldr', 'function', 'gather', 'gather_nd', 'get_current_name_scope', 'get_logger', 'get_static_value', 'grad_pass_through', 'gradients', 'graph_util', 'greater', 'greater_equal', 'group', 'guarantee_const', 'half', 'hessians', 'histogram_fixed_width', 'histogram_fixed_width_bins', 'identity', 'identity_n', 'ifftnd', 'image', 'import_graph_def', 'init_scope', 'initializers', 'inside_function', 'int16', 'int32', 'int64', 'int8', 'io', 'irfftnd', 'is_symbolic_tensor', 'is_tensor', 'keras', 'less', 'less_equal', 'linalg', 'linspace', 'lite', 'load_library', 'load_op_library', 'logical_and', 'logical_not', 'logical_or', 'lookup', 'losses', 'make_ndarray', 'make_tensor_proto', 'map_fn', 'math', 'matmul', 'matrix_square_root', 'maximum', 'meshgrid', 'metrics', 'minimum', 'mlir', 'multiply', 'name_scope', 'negative', 'nest', 'newaxis', 'nn', 'no_gradient', 'no_op', 'nondifferentiable_batch_function', 'norm', 'not_equal', 'numpy_function', 'one_hot', 'ones', 'ones_initializer', 'ones_like', 'optimizers', 'pad', 'parallel_stack', 'pow', 'print', 'profiler', 'py_function', 'qint16', 'qint32', 'qint8', 'quantization', 'queue', 'quint16', 'quint8', 'ragged', 'ragged_fill_empty_rows', 'ragged_fill_empty_rows_grad', 'random', 'random_index_shuffle', 'random_normal_initializer', 'random_uniform_initializer', 'range', 'rank', 'raw_ops', 'realdiv', 'recompute_grad', 'reduce_all', 'reduce_any', 'reduce_logsumexp', 'reduce_max', 'reduce_mean', 'reduce_min', 'reduce_prod', 'reduce_sum', 'register_tensor_conversion_function', 'repeat', 'required_space_to_batch_paddings', 'reshape', 'resource', 'reverse', 'reverse_sequence', 'rfftnd', 'roll', 'round', 'saturate_cast', 'saved_model', 'scalar_mul', 'scan', 'scatter_nd', 'searchsorted', 'security', 'sequence_mask', 'sets', 'shape', 'shape_n', 'sigmoid', 'sign', 'signal', 'sin', 'sinh', 'size', 'slice', 'sort', 'space_to_batch', 'space_to_batch_nd', 'sparse', 'split', 'sqrt', 'square', 'squeeze', 'stack', 'stop_gradient', 'strided_slice', 'string', 'strings', 'subtract', 'summary', 'switch_case', 'sysconfig', 'tan', 'tanh', 'tensor_scatter_nd_add', 'tensor_scatter_nd_max', 'tensor_scatter_nd_min', 'tensor_scatter_nd_sub', 'tensor_scatter_nd_update', 'tensordot', 'test', 'tile', 'timestamp', 'tools', 'tpu', 'train', 'transpose', 'truediv', 'truncatediv', 'truncatemod', 'tuple', 'type_spec_from_value', 'types', 'uint16', 'uint32', 'uint64', 'uint8', 'unique', 'unique_with_counts', 'unravel_index', 'unstack', 'variable_creator_scope', 'variant', 'vectorized_map', 'version', 'where', 'while_loop', 'xla', 'zeros', 'zeros_initializer', 'zeros_like']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # 2.15.1 ì´ ì¶œë ¥ë¼ì•¼ í•¨\n",
    "print(dir(tf))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š MAE: 0.16987108992094166\n",
      "ğŸ“Š RMSE: 0.21432103157700064\n",
      "ğŸ“ˆ RÂ²: 0.23571937062846893\n"
     ]
    }
   ],
   "source": [
    "# 5. ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"ğŸ“Š MAE:\", mae)\n",
    "print(\"ğŸ“Š RMSE:\", rmse)\n",
    "print(\"ğŸ“ˆ RÂ²:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í…ŒìŠ¤íŠ¸ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 1. ëª¨ë¸ ì •ì˜\n",
    "baseline_model = LinearRegression()\n",
    "\n",
    "# 2. í•™ìŠµ\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. ì˜ˆì¸¡\n",
    "y_pred_log = baseline_model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_true = np.expm1(y_test)\n",
    "\n",
    "# 4. RÂ² í‰ê°€\n",
    "r2_linear = r2_score(y_true, y_pred)\n",
    "print(f\"Linear Regression RÂ²: {r2_linear:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_xgb = r2\n",
    "improvement = (r2_xgb - r2_linear) / abs(r2_linear) * 100\n",
    "print(f\"XGBoost ì„±ëŠ¥ í–¥ìƒ: {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "\n",
    "# íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "feat_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feat_df)\n",
    "\n",
    "feat_df.plot(kind='barh', x='Feature', y='Importance', figsize=(8, 6), title='HDL ì˜ˆì¸¡ì—ì„œì˜ íŠ¹ì„± ì¤‘ìš”ë„')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
